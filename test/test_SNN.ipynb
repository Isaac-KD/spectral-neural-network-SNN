{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef83b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from DSN import DeepSpectralNet\n",
    "from Tool import train_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42bb8dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "assert X_test.shape[1]==X_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "53d685d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(\n",
    "        hidden_layer_sizes=(16, 8),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=1e-4,\n",
    "        batch_size=256,\n",
    "        learning_rate_init=1e-3,\n",
    "        max_iter=100,\n",
    "        random_state=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5a0c25a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaac/Library/Python/3.9/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "aef4cea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3042116985225641\n",
      "R²: 0.7667007517035073\n",
      "289\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "def count_params_mlp(model):\n",
    "    return sum(w.size + b.size for w, b in zip(model.coefs_, model.intercepts_))\n",
    "print(count_params_mlp(mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "33d30a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de paramètres : 273\n",
      "Paramètres de la première couche : 108\n"
     ]
    }
   ],
   "source": [
    "d_input = X_train.shape[1]\n",
    "epochs = 50\n",
    "learning_rate = 1e-3\n",
    "n_samples = X.shape[0]\n",
    "batch_size = 128\n",
    "\n",
    "dims = [d_input,4,8,1]\n",
    "dsn = DeepSpectralNet(dims, ortho_mode='hard',use_layernorm=True)\n",
    "\n",
    "# 1. Obtenir le nombre total de paramètres\n",
    "total_params = dsn.get_param_count()\n",
    "print(f\"Nombre total de paramètres : {total_params}\")\n",
    "\n",
    "# 2. Vérifier une couche spécifique\n",
    "layer_params = dsn.layers[0].get_param_count()\n",
    "print(f\"Paramètres de la première couche : {layer_params}\")\n",
    "\n",
    "# ==== Optimiseur et loss ====\n",
    "optimizer = torch.optim.AdamW(dsn.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9a0173a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16512, 8])\n",
      "torch.Size([16512, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
    "\n",
    "# Avant le training\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std()\n",
    "y_train_scaled = (y_train - y_mean) / y_std\n",
    "y_test_scaled = (y_test - y_mean) / y_std\n",
    "\n",
    "y_train_t = torch.tensor(y_train_scaled.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "y_test_t = torch.tensor(y_test_scaled.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(X_train_t.shape)  # (N_train, d_input)\n",
    "print(y_train_t.shape)  # (N_train, 1)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ac7e87cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 | Train Loss: 0.935635 | Val Loss: 0.827196 | LR: 0.001000\n",
      "Epoch 21/300 | Train Loss: 0.304072 | Val Loss: 0.315913 | LR: 0.001000\n",
      "Epoch 41/300 | Train Loss: 0.279435 | Val Loss: 0.276525 | LR: 0.001000\n",
      "Epoch 61/300 | Train Loss: 0.266261 | Val Loss: 0.262419 | LR: 0.001000\n",
      "Epoch 81/300 | Train Loss: 0.254786 | Val Loss: 0.261141 | LR: 0.001000\n",
      "Epoch 101/300 | Train Loss: 0.248889 | Val Loss: 0.248569 | LR: 0.001000\n",
      "Epoch 121/300 | Train Loss: 0.244178 | Val Loss: 0.242819 | LR: 0.001000\n",
      "Epoch 141/300 | Train Loss: 0.239335 | Val Loss: 0.243457 | LR: 0.001000\n",
      "Epoch 161/300 | Train Loss: 0.238572 | Val Loss: 0.242836 | LR: 0.001000\n",
      "Epoch 181/300 | Train Loss: 0.234328 | Val Loss: 0.235281 | LR: 0.000500\n",
      "Epoch 201/300 | Train Loss: 0.232672 | Val Loss: 0.233461 | LR: 0.000250\n",
      "Epoch 221/300 | Train Loss: 0.232198 | Val Loss: 0.234011 | LR: 0.000250\n",
      "Epoch 241/300 | Train Loss: 0.230809 | Val Loss: 0.232681 | LR: 0.000063\n",
      "Epoch 261/300 | Train Loss: 0.230427 | Val Loss: 0.232720 | LR: 0.000063\n",
      "Epoch 281/300 | Train Loss: 0.230181 | Val Loss: 0.232480 | LR: 0.000031\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ======== Training ========\n",
    "    dsn.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for Xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = dsn(Xb)         \n",
    "        loss = criterion(y_pred, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(dsn.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "    scheduler.step(avg_train_loss)\n",
    "\n",
    "    # ======== Validation ========\n",
    "    dsn.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:  \n",
    "            y_pred = dsn(Xb)\n",
    "            loss = criterion(y_pred, yb)\n",
    "            total_val_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(test_loader.dataset)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "\n",
    "    # ======== Logging ========\n",
    "    if epoch % 20 == 0 or epoch == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.6f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.6f} | LR: {current_lr:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "302b9ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfo0lEQVR4nO3dd3xT5eIG8Cc7TfdelBbKnsUipYKAUoYMAcdFRSkIeFFwgQsHCFet417g5xXFAeK6ijhAZQiWJVD23pTVAp10r6RJ3t8fpQdiC6SY5ND2+X4++diclfccA314p0IIIUBERETUQCjlLgARERGRIzHcEBERUYPCcENEREQNCsMNERERNSgMN0RERNSgMNwQERFRg8JwQ0RERA0Kww0RERE1KAw3RERE1KAw3BDVM2PGjEFUVNQNnfv6669DoVA4tkDUoERFRWHIkCFyF4Pob2G4IXIQhUJh12v9+vVyF1UWY8aMgYeHh9zFkF1UVNRVvxsDBw6Uu3hEDYJa7gIQNRRfffWVzfsvv/wSa9asqbG9bdu2f+tzPv30U1it1hs699VXX8VLL730tz6f/r6YmBhMnTq1xvawsDAZSkPU8DDcEDnIww8/bPN+69atWLNmTY3tf1VWVgaDwWD352g0mhsqHwCo1Wqo1fxjL7fw8PDrfi+I6MaxWYrIhfr06YMOHTpg165d6NWrFwwGA15++WUAwLJlyzB48GCEhYVBp9MhOjoa//rXv2CxWGyu8dc+N2fOnIFCocC///1vfPLJJ4iOjoZOp8Ott96KHTt22JxbW58bhUKByZMnY+nSpejQoQN0Oh3at2+PVatW1Sj/+vXr0bVrV+j1ekRHR+Pjjz92eD+eJUuWIDY2Fm5ubggICMDDDz+M8+fP2xyTmZmJsWPHokmTJtDpdAgNDcWwYcNw5swZ6ZidO3diwIABCAgIgJubG5o1a4ZHH330mp89ZMgQNG/evNZ98fHx6Nq1q/R+zZo16NmzJ3x8fODh4YHWrVtL/y8doboZ79SpUxgwYADc3d0RFhaGWbNmQQhhc2xpaSmmTp2KiIgI6HQ6tG7dGv/+979rHAcAX3/9Nbp16waDwQBfX1/06tULq1evrnHcpk2b0K1bN+j1ejRv3hxffvmlzf7KykrMnDkTLVu2hF6vh7+/P3r27Ik1a9Y47BkQ3Sj+E47IxS5evIi77roLDzzwAB5++GEEBwcDABYtWgQPDw9MmTIFHh4eWLt2LaZPn46ioiK89957173u//73PxQXF+Of//wnFAoF3n33Xdxzzz04derUdWt7Nm3ahJ9++glPPPEEPD098f777+Pee+9FWloa/P39AQB79uzBwIEDERoaipkzZ8JisWDWrFkIDAz8+w/lkkWLFmHs2LG49dZbkZSUhKysLPzf//0fNm/ejD179sDHxwcAcO+99+LQoUN48sknERUVhezsbKxZswZpaWnS+/79+yMwMBAvvfQSfHx8cObMGfz000/X/PyRI0di9OjR2LFjB2699VZp+9mzZ7F161bp/8OhQ4cwZMgQdOrUCbNmzYJOp0Nqaio2b95s131WVlYiNze3xnZ3d3e4ublJ7y0WCwYOHIju3bvj3XffxapVqzBjxgyYzWbMmjULACCEwN13341169Zh3LhxiImJwe+//47nn38e58+fx5w5c6TrzZw5E6+//jpuu+02zJo1C1qtFtu2bcPatWvRv39/6bjU1FTcd999GDduHBITE7Fw4UKMGTMGsbGxaN++PYCqoJyUlITx48ejW7duKCoqws6dO7F7927069fPrudA5DSCiJxi0qRJ4q9/xHr37i0AiPnz59c4vqysrMa2f/7zn8JgMIiKigppW2JiooiMjJTenz59WgAQ/v7+Ii8vT9q+bNkyAUD8+uuv0rYZM2bUKBMAodVqRWpqqrRt3759AoD473//K20bOnSoMBgM4vz589K2EydOCLVaXeOatUlMTBTu7u5X3W8ymURQUJDo0KGDKC8vl7b/9ttvAoCYPn26EEKI/Px8AUC89957V73Wzz//LACIHTt2XLdcVyosLBQ6nU5MnTrVZvu7774rFAqFOHv2rBBCiDlz5ggAIicnp07XF0KIyMhIAaDWV1JSknRcYmKiACCefPJJaZvVahWDBw8WWq1W+uylS5cKAOKNN96w+Zz77rtPKBQK6f/riRMnhFKpFCNGjBAWi8XmWKvVWqN8GzdulLZlZ2fXeC6dO3cWgwcPrvP9E7kCm6WIXEyn02Hs2LE1tl/5L/bi4mLk5ubi9ttvR1lZGY4ePXrd644cORK+vr7S+9tvvx0AcOrUqeuem5CQgOjoaOl9p06d4OXlJZ1rsVjwxx9/YPjw4TadXlu0aIG77rrrute3x86dO5GdnY0nnngCer1e2j548GC0adMGy5cvB1D1nLRaLdavX4/8/Pxar1Vdw/Pbb7+hsrLS7jJ4eXnhrrvuwvfff2/TpLN48WJ0794dTZs2tbn+smXLbqhzd1xcHNasWVPj9eCDD9Y4dvLkydLP1U2IJpMJf/zxBwBgxYoVUKlUeOqpp2zOmzp1KoQQWLlyJQBg6dKlsFqtmD59OpRK27/6/9qs2K5dO+n7AwCBgYFo3bq1zXfJx8cHhw4dwokTJ+p8/0TOxnBD5GLh4eHQarU1th86dAgjRoyAt7c3vLy8EBgYKHU6LSwsvO51q3/xVqsOOlcLANc6t/r86nOzs7NRXl6OFi1a1Diutm034uzZswCA1q1b19jXpk0bab9Op8M777yDlStXIjg4GL169cK7776LzMxM6fjevXvj3nvvxcyZMxEQEIBhw4bh888/h9FovG45Ro4cifT0dKSkpAAATp48iV27dmHkyJE2x/To0QPjx49HcHAwHnjgAXz//fd2B52AgAAkJCTUeEVGRtocp1Qqa/QBatWqFQBI/YvOnj2LsLAweHp62hxXPSqv+rmdPHkSSqUS7dq1u275rvd9AIBZs2ahoKAArVq1QseOHfH8889j//791702kSsw3BC52JU1NNUKCgrQu3dv7Nu3D7NmzcKvv/6KNWvW4J133gEAu35pqlSqWreLWjqVOvJcOTzzzDM4fvw4kpKSoNfr8dprr6Ft27bYs2cPgKqaiB9++AEpKSmYPHkyzp8/j0cffRSxsbEoKSm55rWHDh0Kg8GA77//HgDw/fffQ6lU4v7775eOcXNzw8aNG/HHH3/gkUcewf79+zFy5Ej069evRgfw+sie70OvXr1w8uRJLFy4EB06dMBnn32GW265BZ999pmrikl0VQw3RDeB9evX4+LFi1i0aBGefvppDBkyBAkJCTbNTHIKCgqCXq9HampqjX21bbsR1bUWx44dq7Hv2LFjNWo1oqOjMXXqVKxevRoHDx6EyWTCf/7zH5tjunfvjjfffBM7d+7EN998g0OHDuG77767Zjnc3d0xZMgQLFmyBFarFYsXL8btt99eYw4apVKJvn37Yvbs2Th8+DDefPNNrF27FuvWrbuR26+V1Wqt0ax4/PhxAJBGzEVGRuLChQsoLi62Oa66KbP6uUVHR8NqteLw4cMOK5+fnx/Gjh2Lb7/9Funp6ejUqRNef/11h12f6EYx3BDdBKr/pXzlv4xNJhM+/PBDuYpkQ6VSISEhAUuXLsWFCxek7ampqVKfjr+ra9euCAoKwvz5822aj1auXIkjR45g8ODBAKrmBaqoqLA5Nzo6Gp6entJ5+fn5NWqdYmJiAMDupqkLFy7gs88+w759+2yapAAgLy+vxjl1uX5dfPDBB9LPQgh88MEH0Gg06Nu3LwBg0KBBsFgsNscBwJw5c6BQKKQ+UcOHD4dSqcSsWbNq1ATeSA3dxYsXbd57eHigRYsWDr9/ohvBoeBEN4HbbrsNvr6+SExMxFNPPQWFQoGvvvrqpmoWev3117F69Wr06NEDjz/+uPQLtUOHDti7d69d16isrMQbb7xRY7ufnx+eeOIJvPPOOxg7dix69+6NBx98UBoKHhUVhWeffRZAVc1F37598Y9//APt2rWDWq3Gzz//jKysLDzwwAMAgC+++AIffvghRowYgejoaBQXF+PTTz+Fl5cXBg0adN1yDho0CJ6ennjuueegUqlw77332uyfNWsWNm7ciMGDByMyMhLZ2dn48MMP0aRJE/Ts2fO61z9//jy+/vrrGts9PDwwfPhw6b1er8eqVauQmJiIuLg4rFy5EsuXL8fLL78sDcEfOnQo7rjjDrzyyis4c+YMOnfujNWrV2PZsmV45plnpI7iLVq0wCuvvIJ//etfuP3223HPPfdAp9Nhx44dCAsLQ1JS0nXLfaV27dqhT58+iI2NhZ+fH3bu3IkffvjBpgM0kWzkGqZF1NBdbSh4+/btaz1+8+bNonv37sLNzU2EhYWJF154Qfz+++8CgFi3bp103NWGgtc2NBqAmDFjhvT+akPBJ02aVOPcyMhIkZiYaLMtOTlZdOnSRWi1WhEdHS0+++wzMXXqVKHX66/yFC6rHtpc2ys6Olo6bvHixaJLly5Cp9MJPz8/MWrUKHHu3Dlpf25urpg0aZJo06aNcHd3F97e3iIuLk58//330jG7d+8WDz74oGjatKnQ6XQiKChIDBkyROzcufO65aw2atQoAUAkJCTU2JecnCyGDRsmwsLChFarFWFhYeLBBx8Ux48fv+51rzUU/Mr/r9VD50+ePCn69+8vDAaDCA4OFjNmzKgxlLu4uFg8++yzIiwsTGg0GtGyZUvx3nvv2QzxrrZw4ULp+fr6+orevXuLNWvW2JSvtiHevXv3Fr1795bev/HGG6Jbt27Cx8dHuLm5iTZt2og333xTmEym6z4DImdTCHET/dOQiOqd4cOHc0iwE4wZMwY//PDDdTtAE1FN7HNDRHYrLy+3eX/ixAmsWLECffr0kadARES1YJ8bIrJb8+bNMWbMGDRv3hxnz57FRx99BK1WixdeeEHuohERSRhuiMhuAwcOxLfffovMzEzodDrEx8fjrbfeQsuWLeUuGhGRhH1uiIiIqEFhnxsiIiJqUBhuiIiIqEFpdH1urFYrLly4AE9Pzxor4RIREdHNSQiB4uJihIWF1VjZ/q8aXbi5cOECIiIi5C4GERER3YD09HQ0adLkmsc0unDj6ekJoOrheHl5yVwaIiIiskdRUREiIiKk3+PX0ujCTXVTlJeXF8MNERFRPWNPlxJ2KCYiIqIGheGGiIiIGhSGGyIiImpQGG6IiIioQWG4ISIiogaF4YaIiIgaFIYbIiIialAYboiIiKhBYbghIiKiBoXhhoiIiBoUhhsiIiJqUBhuiIiIqEFpdAtnOovRbMHFEhMAIMzHTebSEBERNV6suXGQA+cKcdvba/HQp1vlLgoREVGjxnDjIBpV1aOstAiZS0JERNS4Mdw4iFZd9SiNZqvMJSEiImrcGG4c5HLNDcMNERGRnBhuHESnZrghIiK6GTDcOEh1zY2JzVJERESyYrhxEI1KAQAwWwWsVnYqJiIikgvDjYNUdygGgEora2+IiIjkwnDjINXNUgCbpoiIiOTEcOMg2ivCDee6ISIikg/DjYMolQqolVX9blhzQ0REJB+GGwfiXDdERETykz3czJs3D1FRUdDr9YiLi8P27duvefzcuXPRunVruLm5ISIiAs8++ywqKipcVNprq+5UbGK4ISIiko2s4Wbx4sWYMmUKZsyYgd27d6Nz584YMGAAsrOzaz3+f//7H1566SXMmDEDR44cwYIFC7B48WK8/PLLLi557TjXDRERkfxkDTezZ8/GhAkTMHbsWLRr1w7z58+HwWDAwoULaz1+y5Yt6NGjBx566CFERUWhf//+ePDBB69b2+Mq2ktz3bBZioiISD6yhRuTyYRdu3YhISHhcmGUSiQkJCAlJaXWc2677Tbs2rVLCjOnTp3CihUrMGjQoKt+jtFoRFFRkc3LWbRcgoGIiEh2ark+ODc3FxaLBcHBwTbbg4ODcfTo0VrPeeihh5Cbm4uePXtCCAGz2YyJEydes1kqKSkJM2fOdGjZr6a6WYorgxMREclH9g7FdbF+/Xq89dZb+PDDD7F792789NNPWL58Of71r39d9Zxp06ahsLBQeqWnpzutfJdrbjjPDRERkVxkq7kJCAiASqVCVlaWzfasrCyEhITUes5rr72GRx55BOPHjwcAdOzYEaWlpXjsscfwyiuvQKmsmdV0Oh10Op3jb6AW7FBMREQkP9lqbrRaLWJjY5GcnCxts1qtSE5ORnx8fK3nlJWV1QgwKpUKACCE/LUlWs5zQ0REJDvZam4AYMqUKUhMTETXrl3RrVs3zJ07F6WlpRg7diwAYPTo0QgPD0dSUhIAYOjQoZg9eza6dOmCuLg4pKam4rXXXsPQoUOlkCMndigmIiKSn6zhZuTIkcjJycH06dORmZmJmJgYrFq1SupknJaWZlNT8+qrr0KhUODVV1/F+fPnERgYiKFDh+LNN9+U6xZsaC4NBWeHYiIiIvkoxM3QnuNCRUVF8Pb2RmFhIby8vBx67ce+3InVh7Pw5ogOGBUX6dBrExERNWZ1+f1dr0ZL3eyk5RdYc0NERCQbhhsHYodiIiIi+THcOBDnuSEiIpIfw40DcYZiIiIi+THcOJCGzVJERESyY7hxIKlZijU3REREsmG4cSDtpXluTKy5ISIikg3DjQOxWYqIiEh+DDcOVN0sxQ7FRERE8mG4caDLNTccCk5ERCQXhhsHYodiIiIi+THcOFD1DMXsUExERCQfhhsH0qirRkuxQzEREZF8GG4cSKtSAeDCmURERHJiuHEgDee5ISIikh3DjQNp1JznhoiISG4MNw6kq+5QzGYpIiIi2TDcONDlmhvOc0NERCQXhhsH0rLmhoiISHYMNw6k4Tw3REREsmO4cSAt57khIiKSHcONA1XPc8PlF4iIiOTDcONA1TMUs1mKiIhIPgw3DqS9YlVwIThiioiISA4MNw5UPRQcYO0NERGRXBhuHKi65gbgXDdERERyYbhxIM2V4YadiomIiGTBcONAKqUCKiU7FRMREcmJ4cbBpJXBWXNDREQkC4YbB9NylmIiIiJZMdw4mFZaPJPhhoiISA4MNw4mzXVj5mgpIiIiOTDcOFj1XDcmi0XmkhARETVODDcOJq0MzpobIiIiWTDcONjlJRjY54aIiEgODDcOJjVLcSg4ERGRLBhuHEx7aZ4b1twQERHJg+HGwbRqznNDREQkJ4YbB6vuUGxksxQREZEsGG4cjB2KiYiI5MVw42BadigmIiKSFcONgzHcEBERyYvhxsF0DDdERESyYrhxMK4KTkREJC+GGwdjsxQREZG8bopwM2/ePERFRUGv1yMuLg7bt2+/6rF9+vSBQqGo8Ro8eLALS3x11eGGQ8GJiIjkIXu4Wbx4MaZMmYIZM2Zg9+7d6Ny5MwYMGIDs7Oxaj//pp5+QkZEhvQ4ePAiVSoX777/fxSWvnValAsBmKSIiIrnIHm5mz56NCRMmYOzYsWjXrh3mz58Pg8GAhQsX1nq8n58fQkJCpNeaNWtgMBhunnDDZikiIiJZyRpuTCYTdu3ahYSEBGmbUqlEQkICUlJS7LrGggUL8MADD8Dd3d1ZxawTzaW1pRhuiIiI5KGW88Nzc3NhsVgQHBxssz04OBhHjx697vnbt2/HwYMHsWDBgqseYzQaYTQapfdFRUU3XmA7cCg4ERGRvGRvlvo7FixYgI4dO6Jbt25XPSYpKQne3t7SKyIiwqll4sKZRERE8pI13AQEBEClUiErK8tme1ZWFkJCQq55bmlpKb777juMGzfumsdNmzYNhYWF0is9Pf1vl/ta2OeGiIhIXrKGG61Wi9jYWCQnJ0vbrFYrkpOTER8ff81zlyxZAqPRiIcffviax+l0Onh5edm8nEkaLcVwQ0REJAtZ+9wAwJQpU5CYmIiuXbuiW7dumDt3LkpLSzF27FgAwOjRoxEeHo6kpCSb8xYsWIDhw4fD399fjmJflTTPDZuliIiIZCF7uBk5ciRycnIwffp0ZGZmIiYmBqtWrZI6GaelpUGptK1gOnbsGDZt2oTVq1fLUeRrqg43lay5ISIikoXs4QYAJk+ejMmTJ9e6b/369TW2tW7dGkIIJ5fqxnBtKSIiInnV69FSNyN2KCYiIpIXw42DcZ4bIiIieTHcOBjnuSEiIpIXw42DSX1uWHNDREQkC4YbB2OfGyIiInkx3DjYlc1SN+uILiIiooaM4cbBqsMNwH43REREcmC4cbDqPjcAm6aIiIjkwHDjYAw3RERE8mK4cTClUgGNSgGAzVJERERyYLhxAg2HgxMREcmG4cYJOByciIhIPgw3TlDd78bIcENERORyDDdOwCUYiIiI5MNw4wRsliIiIpIPw40TcH0pIiIi+TDcOIHuUs1NJZuliIiIXI7hxgnYLEVERCQfhhsnYIdiIiIi+TDcOAGHghMREcmH4cYJ2CxFREQkH4YbJ9CqVQAYboiIiOTAcOME0lBw9rkhIiJyOYYbJ2CzFBERkXzUN3JSZWUlMjMzUVZWhsDAQPj5+Tm6XPWajuGGiIhINnbX3BQXF+Ojjz5C79694eXlhaioKLRt2xaBgYGIjIzEhAkTsGPHDmeWtd7gUHAiIiL52BVuZs+ejaioKHz++edISEjA0qVLsXfvXhw/fhwpKSmYMWMGzGYz+vfvj4EDB+LEiRPOLvdNjcsvEBERyceuZqkdO3Zg48aNaN++fa37u3XrhkcffRTz58/H559/jj///BMtW7Z0aEHrk+qaG85zQ0RE5Hp2hZtvv/3WrovpdDpMnDjxbxWoIWCHYiIiIvk4bLSUEALZ2dmOuly9puFQcCIiItnYHW4MBgNycnKk94MHD0ZGRob0Pjs7G6GhoY4tXT11uebGInNJiIiIGh+7w01FRQWEENL7jRs3ory83OaYK/c3Zjp2KCYiIpKNQyfxUygUjrxcvcWh4ERERPLhDMVOwA7FRERE8rE73CgUCpuamb++p8s4zw0REZF87F5+QQiBVq1aSYGmpKQEXbp0gVKplPZTlcvNUnwmRERErmZ3uPn888+dWY4GhaOliIiI5GN3uElMTHRmORoUdigmIiKSzw2tCl6toqICixcvRmlpKfr169eol1y4UnWfm0ozm6WIiIhcze5wM2XKFFRWVuK///0vAMBkMiE+Ph6HDh2CwWDACy+8gDVr1iA+Pt5pha0vqmcormTNDRERkcvZPVpq9erV6Nevn/T+m2++wdmzZ3HixAnk5+fj/vvvxxtvvOGUQtY3alVVp2uGGyIiItezO9ykpaWhXbt20vvVq1fjvvvuQ2RkJBQKBZ5++mns2bPHKYWsb6RmKY6WIiIicjm7w41SqbQZ7r1161Z0795deu/j44P8/HzHlq6eqq65MVtZc0NERORqdoebtm3b4tdffwUAHDp0CGlpabjjjjuk/WfPnkVwcLDjS1gPqZWXa244/w8REZFr2d2h+IUXXsADDzyA5cuX49ChQxg0aBCaNWsm7V+xYgW6devmlELWN9XNUgBgtgpoVJzJmYiIyFXsrrkZMWIEVqxYgU6dOuHZZ5/F4sWLbfYbDAY88cQTDi9gfaS+IsyY2e+GiIjIpeq0cGbfvn0xZ84cvPjiizAYDDb7ZsyYgT59+tS5APPmzUNUVBT0ej3i4uKwffv2ax5fUFCASZMmITQ0FDqdDq1atcKKFSvq/LnOpLmi5oYT+REREbmW3c1SaWlpdh3XtGlTuz988eLFmDJlCubPn4+4uDjMnTsXAwYMwLFjxxAUFFTjeJPJhH79+iEoKAg//PADwsPDcfbsWfj4+Nj9ma6gsam5YbghIiJyJbvDzZX9a6o7yV65KrgQAgqFAhaL/espzZ49GxMmTMDYsWMBAPPnz8fy5cuxcOFCvPTSSzWOX7hwIfLy8rBlyxZoNBoAQFRUlN2f5yoKhQJqpQJmq+BwcCIiIhezO9woFAo0adIEY8aMwdChQ6FW/62VG2AymbBr1y5MmzZN2qZUKpGQkICUlJRaz/nll18QHx+PSZMmYdmyZQgMDMRDDz2EF198ESqVqtZzjEYjjEaj9L6oqOhvldtealV1uGHNDRERkSvZ3efm3LlzePzxx/Hdd99h8ODB+Oqrr6DVatG5c2ebl71yc3NhsVhqDB8PDg5GZmZmreecOnUKP/zwAywWC1asWIHXXnsN//nPf645M3JSUhK8vb2lV0REhN1l/Du4BAMREZE87A43ISEhePHFF3H06FH88MMPyM/PR1xcHLp3745PP/0UVhdMWGe1WhEUFIRPPvkEsbGxGDlyJF555RXMnz//qudMmzYNhYWF0is9Pd3p5QQuhxuzlc1SRERErlSn0VLVevbsiQULFuDEiRMwGAyYOHEiCgoK6nSNgIAAqFQqZGVl2WzPyspCSEhIreeEhoaiVatWNk1Qbdu2RWZmJkwmU63n6HQ6eHl52bxcQa3k+lJERERyuKFws2XLFowfPx6tWrVCSUkJ5s2bV+cRS1qtFrGxsUhOTpa2Wa1WJCcnX3Vl8R49eiA1NdWmluj48eMIDQ2FVqu9kVtxGg3XlyIiIpKF3eEmIyMD77zzDtq0aYMRI0bAy8sLmzdvxvbt2zFx4kQolXXPSVOmTMGnn36KL774AkeOHMHjjz+O0tJSafTU6NGjbTocP/7448jLy8PTTz+N48ePY/ny5XjrrbcwadKkOn+2s1UPB+dQcCIiIteye8hT06ZNER4ejsTERNx9993QaDSwWq3Yv3+/zXGdOnWy+8NHjhyJnJwcTJ8+HZmZmYiJicGqVaukTsZpaWk2oSkiIgK///47nn32WXTq1Anh4eF4+umn8eKLL9r9ma5SXXPDSfyIiIhcSyHsXNnxypBRPb/NX0+t6zw3cigqKoK3tzcKCwud2v/mrv/7E0cyivDlo93Qq1Wg0z6HiIioMajL72+7a25Onz79twvWmGhV7FBMREQkB7vDTWRkpDPL0eCo2aGYiIhIFnb1ArZ3Xalq58+fv6HCNCQcCk5ERCQPu8LNrbfein/+85/YsWPHVY8pLCzEp59+ig4dOuDHH390WAHrK626ehI/hhsiIiJXsqtZ6vDhw3jzzTfRr18/6PV6xMbGIiwsDHq9Hvn5+Th8+DAOHTqEW265Be+++y4GDRrk7HLf9C7X3LBZioiIyJXsqrnx9/fH7NmzkZGRgQ8++AAtW7ZEbm4uTpw4AQAYNWoUdu3ahZSUFAabS7i2FBERkTzqtLS3m5sb7rvvPtx3333OKk+DIa0txZobIiIil7qh5Rfo+jQcCk5ERCQLhhsn4VBwIiIieTDcOAlrboiIiOTBcOMkl/vcMNwQERG5EsONk6iV1QtnslmKiIjIleocbr744gssX75cev/CCy/Ax8cHt912G86ePevQwtVnGnVVsxRrboiIiFyrzuHmrbfegpubGwAgJSUF8+bNw7vvvouAgAA8++yzDi9gfaVRVs9QzJobIiIiV6rTPDcAkJ6ejhYtWgAAli5dinvvvRePPfYYevTogT59+ji6fPVWdZ8bE2tuiIiIXKrONTceHh64ePEiAGD16tXo168fAECv16O8vNyxpavH1Co2SxEREcmhzjU3/fr1w/jx49GlSxccP35cWm7h0KFDiIqKcnT56q3LQ8HZLEVERORKda65mTdvHuLj45GTk4Mff/wR/v7+AIBdu3bhwQcfdHgB6yuuLUVERCSPOtfc+Pj44IMPPqixfebMmQ4pUEOhZrghIiKSRZ1rblatWoVNmzZJ7+fNm4eYmBg89NBDyM/Pd2jh6jOt1OeGzVJERESuVOdw8/zzz6OoqAgAcODAAUydOhWDBg3C6dOnMWXKFIcXsL66PIkfa26IiIhcqc7NUqdPn0a7du0AAD/++COGDBmCt956C7t375Y6FxOgUVcvv8CaGyIiIleqc82NVqtFWVkZAOCPP/5A//79AQB+fn5SjQ4BGuWlZikra26IiIhcqc41Nz179sSUKVPQo0cPbN++HYsXLwYAHD9+HE2aNHF4AesrtYprSxEREcmhzjU3H3zwAdRqNX744Qd89NFHCA8PBwCsXLkSAwcOdHgB6ysNJ/EjIiKSRZ1rbpo2bYrffvutxvY5c+Y4pEANBee5ISIikkedww0AWCwWLF26FEeOHAEAtG/fHnfffTdUKpVDC1efVYcbdigmIiJyrTqHm9TUVAwaNAjnz59H69atAQBJSUmIiIjA8uXLER0d7fBC1kfVa0txKDgREZFr1bnPzVNPPYXo6Gikp6dj9+7d2L17N9LS0tCsWTM89dRTzihjvaRlzQ0REZEs6lxzs2HDBmzduhV+fn7SNn9/f7z99tvo0aOHQwtXn6mlhTNZc0NERORKda650el0KC4urrG9pKQEWq3WIYVqCKpnKGa4ISIicq06h5shQ4bgsccew7Zt2yCEgBACW7duxcSJE3H33Xc7o4z1ktQsZWWzFBERkSvVOdy8//77iI6ORnx8PPR6PfR6PXr06IEWLVpg7ty5Tihi/cRmKSIiInnUuc+Nj48Pli1bhtTUVGkoeNu2bdGiRQuHF64+uzzPTVXtlkKhkLlEREREjcMNzXMDAC1atLAJNPv370fXrl1hMpkcUrD6rnqGYqCqaerK90REROQ8dW6WuhohBCwWi6MuV+9V19wAHA5ORETkSg4LN2RLfUVNDSfyIyIich2GGyfRKK+suWG4ISIichW7+9wUFRVdc39tc980ZkqlAiqlAharQCWbpYiIiFzG7nDj4+NzzRE/HBFUk1oKN6y5ISIichW7w826deucWY4GSatSwmi2ciI/IiIiF7I73PTu3duZ5WiQOJEfERGR67FDsRNdnsiP4YaIiMhVGG6c6MpZiomIiMg1GG6cqLpZikPBiYiIXOemCDfz5s1DVFQU9Ho94uLisH379qseu2jRIigUCpuXXq93YWntV11zw0n8iIiIXEf2cLN48WJMmTIFM2bMwO7du9G5c2cMGDAA2dnZVz3Hy8sLGRkZ0uvs2bMuLLH91Mrqmhs2SxEREblKnRfOHDFiRK3z2VTXoLRo0QIPPfQQWrdubdf1Zs+ejQkTJmDs2LEAgPnz52P58uVYuHAhXnrppVrPUSgUCAkJqWvRXU6rZodiIiIiV6tzzY23tzfWrl2L3bt3S81Ce/bswdq1a2E2m7F48WJ07twZmzdvvu61TCYTdu3ahYSEhMsFUiqRkJCAlJSUq55XUlKCyMhIREREYNiwYTh06FBdb8Mlqmtu2KGYiIjIdeocbkJCQvDQQw/h1KlT+PHHH/Hjjz/i5MmTePjhhxEdHY0jR44gMTERL7744nWvlZubC4vFguDgYJvtwcHByMzMrPWc1q1bY+HChVi2bBm+/vprWK1W3HbbbTh37lytxxuNRhQVFdm8XKW6z43ZypobIiIiV6lzuFmwYAGeeeYZKK9YGFKpVOLJJ5/EJ598AoVCgcmTJ+PgwYMOLWi1+Ph4jB49GjExMejduzd++uknBAYG4uOPP671+KSkJHh7e0uviIgIp5SrNpznhoiIyPXqHG7MZjOOHj1aY/vRo0dhsVgAAHq93q51pgICAqBSqZCVlWWzPSsry+4+NRqNBl26dEFqamqt+6dNm4bCwkLplZ6ebtd1HUGaodjMZikiIiJXqXO4eeSRRzBu3DjMmTMHmzZtwqZNmzBnzhyMGzcOo0ePBgBs2LAB7du3v+61tFotYmNjkZycLG2zWq1ITk5GfHy8XeWxWCw4cOAAQkNDa92v0+ng5eVl83IVLYeCExERuVydR0vNmTMHwcHBePfdd6Ual+DgYDz77LNSP5v+/ftj4MCBdl1vypQpSExMRNeuXdGtWzfMnTsXpaWl0uip0aNHIzw8HElJSQCAWbNmoXv37mjRogUKCgrw3nvv4ezZsxg/fnxdb8XpqkdLmcwMN0RERK5S53CjUqnwyiuv4JVXXpE65/61NqRp06Z2X2/kyJHIycnB9OnTkZmZiZiYGKxatUrqZJyWlmbTvyc/Px8TJkxAZmYmfH19ERsbiy1btqBdu3Z1vRWn06lVAAAjww0REZHLKIQQjapDSFFREby9vVFYWOj0JqppPx3At9vT8GxCKzyd0NKpn0VERNSQ1eX3d5373GRlZeGRRx5BWFgY1Go1VCqVzYsu01U3S13qaE1ERETOV+dmqTFjxiAtLQ2vvfYaQkND7RoV1VhVhxtjJZuliIiIXKXO4WbTpk34888/ERMT44TiNCxSh2KOliIiInKZOjdLRUREoJF107lhrLkhIiJyvTqHm7lz5+Kll17CmTNnnFCchoU1N0RERK5X52apkSNHoqysDNHR0TAYDNBoNDb78/LyHFa4+q56KDjnuSEiInKdOoebuXPnOqEYDVN1zY3RzNFSRERErlLncJOYmOiMcjRIUp8b1twQERG5jF3hpqioSJowp3pW4qtx5dpNNzstww0REZHL2RVufH19kZGRgaCgIPj4+NQ6t40QAgqFQloZnK5YOJPhhoiIyGXsCjdr166Fn58fAGDdunVOLVBDotOwQzEREZGr2RVuevfuXevPdG3VNTfsUExEROQ6de5QDAAFBQXYvn07srOzYbXa1kqMHj3aIQVrCHQaznNDRETkanUON7/++itGjRqFkpISeHl52fS/USgUDDdXkGpuOEMxERGRy9R5huKpU6fi0UcfRUlJCQoKCpCfny+9OIGfLT1rboiIiFyuzuHm/PnzeOqpp2AwGJxRngZFq2KHYiIiIlerc7gZMGAAdu7c6YyyNDic54aIiMj16tznZvDgwXj++edx+PBhdOzYscbaUnfffbfDClffVc9QbLEKmC1WqFV1zpJERERUR3UONxMmTAAAzJo1q8Y+TuJnq7rmBqjqd8NwQ0RE5Hx1Djd/HfpNV6e7MtyYrTBoZSwMERFRI8GqBCdSq5RQXhopz07FRERErmFXzc3777+Pxx57DHq9Hu+///41j33qqaccUrCGQqdWobzSwk7FRERELmJXuJkzZw5GjRoFvV6POXPmXPU4hULBcPMXWrWS4YaIiMiF7Ao3p0+frvVnur7Lw8HZ0ZqIiMgV2OfGyao7FbPPDRERkWvc0MKZ586dwy+//IK0tDSYTCabfbNnz3ZIwRoKLcMNERGRS9U53CQnJ+Puu+9G8+bNcfToUXTo0AFnzpyBEAK33HKLM8pYr+nUVUswsM8NERGRa9S5WWratGl47rnncODAAej1evz4449IT09H7969cf/99zujjPUaa26IiIhcq87h5siRIxg9ejQAQK1Wo7y8HB4eHpg1axbeeecdhxewvtNxfSkiIiKXqnO4cXd3l/rZhIaG4uTJk9K+3Nxcx5WsgZA6FHNZCiIiIpeoc5+b7t27Y9OmTWjbti0GDRqEqVOn4sCBA/jpp5/QvXt3Z5SxXtOq2CxFRETkSnUON7Nnz0ZJSQkAYObMmSgpKcHixYvRsmVLjpSqhU7DZikiIiJXqlO4sVgsOHfuHDp16gSgqolq/vz5TilYQ8GaGyIiIteqU58blUqF/v37Iz8/31nlaXA4FJyIiMi16tyhuEOHDjh16pQzytIgaTlaioiIyKXqHG7eeOMNPPfcc/jtt9+QkZGBoqIimxfZ4vILRERErmV3n5tZs2Zh6tSpGDRoEADg7rvvhkKhkPYLIaBQKGDhkGcbXDiTiIjItewONzNnzsTEiROxbt06Z5anweEMxURERK5ld7gRQgAAevfu7bTCNETsUExERORadepzc2UzFNmHNTdERESuVad5blq1anXdgJOXl/e3CtTQsEMxERGRa9Up3MycORPe3t7OKkuDxA7FRERErlWncPPAAw8gKCjIWWVpkC4vnMmaGyIiIlewu88N+9vcmOpwY6xkuCEiInIFu8NN9Wgpqhsta26IiIhcyu5mKauVv5xvRPVQcHYoJiIico06L7/gDPPmzUNUVBT0ej3i4uKwfft2u8777rvvoFAoMHz4cOcW8G/g2lJERESuJXu4Wbx4MaZMmYIZM2Zg9+7d6Ny5MwYMGIDs7OxrnnfmzBk899xzuP32211U0htzuc8NR0sRERG5guzhZvbs2ZgwYQLGjh2Ldu3aYf78+TAYDFi4cOFVz7FYLBg1ahRmzpyJ5s2bu7C0dWfQVrX8lRjNMpeEiIiocZA13JhMJuzatQsJCQnSNqVSiYSEBKSkpFz1vFmzZiEoKAjjxo277mcYjUZZVy73c9cCAIoqzDCzUzEREZHTyRpucnNzYbFYEBwcbLM9ODgYmZmZtZ6zadMmLFiwAJ9++qldn5GUlARvb2/pFRER8bfLXRfebhpUj6IvKK906WcTERE1RrI3S9VFcXExHnnkEXz66acICAiw65xp06ahsLBQeqWnpzu5lLZUSgW83TQAgPxSk0s/m4iIqDGq0wzFjhYQEACVSoWsrCyb7VlZWQgJCalx/MmTJ3HmzBkMHTpU2lY9RF2tVuPYsWOIjo62OUen00Gn0zmh9PbzM2hRUFaJPIYbIiIip5O15kar1SI2NhbJycnSNqvViuTkZMTHx9c4vk2bNjhw4AD27t0rve6++27ccccd2Lt3r8ubnOzlY7hUc1PGZikiIiJnk7XmBgCmTJmCxMREdO3aFd26dcPcuXNRWlqKsWPHAgBGjx6N8PBwJCUlQa/Xo0OHDjbn+/j4AECN7TeT6k7F+WWsuSEiInI22cPNyJEjkZOTg+nTpyMzMxMxMTFYtWqV1Mk4LS0NSmW96hpUg6+hKtywWYqIiMj5ZA83ADB58mRMnjy51n3r16+/5rmLFi1yfIEczPdSzU0Ba26IiIicrn5XidQTl2tu2OeGiIjI2RhuXMDPvbpDMWtuiIiInI3hxgV82OeGiIjIZRhuXMCPfW6IiIhchuHGBThaioiIyHUYblzA99IkfkUVZlRy8UwiIiKnYrhxAZvFMzlLMRERkVMx3LiAWqWUFs9kvxsiIiLnYrhxEfa7ISIicg2GGxfxNXCuGyIiIldguHGR6uHgF1lzQ0RE5FQMNy4S6KkDAGQXGWUuCRERUcPGcOMiwV56AEB2cYXMJSEiImrYGG5cpDrcZBYy3BARETkTw42LhFwKN1lsliIiInIqhhsXCfK61OeGzVJEREROxXDjItU1N7klJpjMXIKBiIjIWRhuXMTXoIVGVbUGQ04Jm6aIiIicheHGRZRKBYI82amYiIjI2RhuXCi4ut9NEcMNERGRszDcuFCI96WaG4YbIiIip2G4caHqZikOByciInIehhsXqq65YbMUERGR8zDcuFB1nxs2SxERETkPw40LBUuzFDPcEBEROQvDjQs19TMAAM5eLENRRaXMpSEiImqYGG5cqImvAc0D3WG2Cvx5PFfu4hARETVIDDcu1rdNEAAg+WiWzCUhIiJqmBhuXKxv22AAwPpjObBYhcylISIiangYblwsNtIXXno18kpN2JueX2N/ucmCgXM3YvwXO2QoHRERUf3HcONiGpUSvVtXNU39cSS7xv49afk4mlmMP45ko7CcnY6JiIjqiuFGBgltq8LN2trCTXqB9HNqdomrikRERNRgMNzIoHerQCgVwLGsYqTnldns23dFuDnJcENERFRnDDcy8DFo0TXSDwCw9ujl2hshBPZeEW5OZBe7umhERET1HsONTPq2rR4SfjncZBRWILv48qKabJYiIiKqO4YbmVQPCd+SmouLJVWBprpJSqNSAABOMNwQERHVGcONTFoEeaBjuDfMVoGley/gQkE5vtp6FgCQcCn4nMsvR5nJLGcxiYiI6h2GGxnd37UJAGDhptPoP2cjtpy8CIUCSLwtCn7uWgDAqZxSOYtIRERU7zDcyOjuzmHQqpU4X1COEqMZMRE++GVST3Rv7o8WgR4A2KmYiIiorhhuZORj0GJwx1AAVWtOffdYd3Rs4g0AaBfmBQBYezTnutdJzS7GnDXH8fR3e3AmlzU9RETUuKnlLkBjN2tYewyLCUOPFgHQqC5nzftim2DRljNYeSAD2YPbIshLX+v5ZSYzhn2wGaUmCwDA202DWcM6uKTsRERENyPW3MjMU69Bn9ZBNsEGADqEe6NrpC/MVoFvt6cDAE5kFePsRduamaOZxVKwAYBjmWzGIiKixo3h5ib2SHwkAOCrrWewOTUXg97/E/d8uAVG8+UwcySjCAAQ4FHVAfl4VjGE4GrjRETUeDHc3MTu6hCK5gHuyC0x4ZEF21BpEbhYasL203nSMdXhZkinMCgUQH5ZJXJLTNL+7KIKTF92EOfyy2pcn4iIqCFiuLmJadVKzH0gBmqlAtYrKmPWHc1BidGMcpMFRzKqmqG6NPVBpJ8BQFXtTbUP1qXiy5SzeO/3Yy4tOxERkVxuinAzb948REVFQa/XIy4uDtu3b7/qsT/99BO6du0KHx8fuLu7IyYmBl999ZULS+tanZr44NXBbWHQqnDPLeEAgJUHM9DnvXUYMHcjjl6quWkb6oVWwZ4AbMPNtlNVtTx/nsiF1crmKiIiavhkDzeLFy/GlClTMGPGDOzevRudO3fGgAEDkJ2dXevxfn5+eOWVV5CSkoL9+/dj7NixGDt2LH7//XcXl9x1xvRohsOzBmLm3e2hUSmQUViB3BIT0vLKUGqyQKtSonmAe41wk19qwrFLP+eVmnDwQqFs90BEROQqsoeb2bNnY8KECRg7dizatWuH+fPnw2AwYOHChbUe36dPH4wYMQJt27ZFdHQ0nn76aXTq1AmbNm1yccldz1Ovwa1RVauJKxSXt7cM9oBapUSrkOpwU7Um1c6z+Tbnbzh2/TlziIiI6jtZw43JZMKuXbuQkJAgbVMqlUhISEBKSsp1zxdCIDk5GceOHUOvXr2cWdSbxvjbm6F5oDs+fjgWod5Vc9+0Da2a8K9VcNWsxsczi2G1Cmw/fREA4Kmvms5ow3GGGyIiavhkncQvNzcXFosFwcHBNtuDg4Nx9OjRq55XWFiI8PBwGI1GqFQqfPjhh+jXr1+txxqNRhiNRul9UVGRYwovkzvbBOPONlXPq9IiMOOXQxgeU9UXp3mABzx0ahQbzdh4IkcaVfXPXs3x79XHsTstH0UVlfDSa2QrPxERkbPJ3ix1Izw9PbF3717s2LEDb775JqZMmYL169fXemxSUhK8vb2lV0REhGsL60SDO4Vi56sJ6NkyAEDV6KqRt1bd3xvLj+DA+ao+NsO7hKOpnwFWAexNK5CruERERC4ha7gJCAiASqVCVlaWzfasrCyEhIRc9TylUokWLVogJiYGU6dOxX333YekpKRaj502bRoKCwulV3p6ukPv4WYz5rYoKBVAanYJrKJqcc4mvgbERvoCqNkPh4iIqKGRNdxotVrExsYiOTlZ2ma1WpGcnIz4+Hi7r2O1Wm2anq6k0+ng5eVl82rIIvwMGNihKhi2CPJA0j0dAQC3XAo3uxluiIiogZN94cwpU6YgMTERXbt2Rbdu3TB37lyUlpZi7NixAIDRo0cjPDxcqplJSkpC165dER0dDaPRiBUrVuCrr77CRx99JOdt3FSmD2mPCF8DHu4eCXdd1f/irpfCzZ60fJgtVqhV9bJFkoiI6LpkDzcjR45ETk4Opk+fjszMTMTExGDVqlVSJ+O0tDQolZd/EZeWluKJJ57AuXPn4ObmhjZt2uDrr7/GyJEj5bqFm06Itx7TBrW12dYq2BOelzobH8sqRvswb5zLL0OYtxuUSsVVrkRERFT/KEQjW2WxqKgI3t7eKCwsbPBNVH/1yIJt+PNELmYMbQej2Yq3Vx7FE32i8cLANnIXjYiI6Jrq8vubbRONSHy0PwBg9prj+PeltaY++/N0rYtqWqwCBWWmWlcYF0Jg19l8lJnMzi0wERHRDWC4aUTG3tYMsZG+KK4ww2wVUCsVMFmseG7JPry14ghO5VTNbGyxCtzz4WbEzFqDdtN/x5KdtiPMVh7MxL0fbcGMZYfkuA0iIqJrYrhpRNy0KixMvBW3RfujcxNvfD72VgDA1lN5+GTjKTyyYDtyio1YfSgT+85VzZFTXmnBvHWpNjU4a49Wrfv1+6FMmC1W198IERHRNcjeoZhcy9ugwf8mdIcQAgqFArOGtcfus/nYnVaAtLwyjPtiByotVUFmbI8ofLc9HWculmHfuULERPgAAHacqZr5uKjCjD3pBdJ6V/mlJny3Ix392gWhRZCnLPdHRETEcNNIKS6tvDk6Pgqj46NwKqcEw+dtxv5LNTZ6jRKT72iBiyUm/LLvAt5ddRRWITAsJhxnL17uo7P+WDZujfLD9tN5GL1wGyoqrdicmouvx8fJcl9ERERsliIAQPNADyyb3BO9WgUCAMb1bAZ/Dx2GdwkDAGw5eRFbT+Vh2k8HbM5bdzQHeaUmjP9iByoqq5qoNqXmoqDMhBd+2IdNJ3JdeyNERNTocSg42RBCIKfEiEAPHRQKBSotVtz29lrkFBth0KpQZrIAqFrXavn+DADAbdH+2HLyItqEeCI1uwRmq8CQTqH4bX8GfAwarH+uD7zdNDCarVApFdBwAkEiIqqjuvz+Zrih6zqVU4KcYiMyCivwzOK9AID/PtgFKw5kYOXBTOm4xY91xwfrUvHnX2prukb64kR2CQrLK+Fj0ODXyT0R4Wdw5S0QEVE9x3luyKGaB3ogrrk/hnYOQ9dIX/gaNOjRIgD/90AXjI6PBADcF9sEcc39pQU6r7TzbD4KyysBAAVllfh661mXlp+IiBoX1txQnVRarBAC0Kov5+KcYiP83bVQKhX480QOHlmwHQDQOcIHMU288eeJXDzeJxo6jQpPfbsHfu5apEy7Ezq1yubaheWVWLwjDRcKKvD8gNbSulhERER1+f3N3x5UJ7X1lwn01Ek/x0T4QKEAhAD6twvGpDtaSPvMFive9NIhq8iIlQcyEdfcD7/uu4DbogOgUirwwCdbpRoeN60KL9q5LIQQAt/tSEfLIA90vTQsnYiIGi82S5FDeeo1uL1lINy1KgztFGazT61SYmTXCADAM4v3osfba/HWiqN44JOteOKb3Sgsr0SYtx4AsHDTaVwoKJfO/XnPOYxbtAPnr9hWbe3RbEz76QAe/2Z3rctFZBSWY9Hm0zCZrdhxJg9PfLMLGYU1r0NERA0Dww053CePxGLTi3eiqX/NTsOP9myGXq0CoVQAVgH4u2tRYjTjdG4pAjx0+PXJnujWzA9GsxXvXVr/KquoAi//dBDJR7Mx8atdqKi02Fzz+0vLQ+QUG3E8q8RmnxACj3+9G6//ehiLd6Th/eQTWHEgEx+sTXXS3RMRkdzYLEUOp9eooNeoat3nY9Diy0e7Ib/UhFKTGV5uGjz06VYczyzBe/d3gr+HDi8PaosRH27Gz3vOY2jnUPx+MAvllwLNgfOF+OdXu/BEn2hkFlUg0FOH5CPZ0vW3nMxF65DLsyNvTr2IvekFAIAdZ/Kx79LPv+67gNeGtLtqOYmIqP5ih2KSncUqkFdqsum786/fDmPBptPQqZUwmqsmB3yufyvM/eMEzNarf2X7twvGJ6O7Su9HfpyCbaerlovw0KlRYry8kvm8h27B4E6hdpfTaLZg66k89Ij2h5pz9RARuRSHglO9olIqbIINADw/oDWaB7pLwWZ8z2aYfGdL/PpkTyS0DYKvQYMO4Ze/3PfFNgEAbD11EZZL4Wf1oUxsO50HjapqqYkrgw0AzPz1EB5ZsA1nL5bWWq61R7OkdbQA4D+rjyNx4XZ8tun0Ve/lSEYRRn22FfvPFdh59zWtO5aNb7en3fD5RESNHZul6Kak16jw3WPdsTetADFNfRDkWdXRuG2oFz5LvFU67uD5QhzLLMbQzmH4/WAmiirM+Ndvh3FLpC9m/XoYADD+9ub4/WAmTuVWhZjbWwZgy8mLyC42IrvYiLl/nMCckTHSNYUQ+HZ7Ol7++QC0KiXWTOmFCF8Dlu45DwBYdTATE3tH11rujzecxObUi3jv92P4alzd19eyWAWe/N8elBjN6BjujQ7h3nW+BhFRY8dwQzetIE89+rcPueYxHa4IALe3CsCKA5lYtOUMFm05AwBoEeSBp/u2RGZhhRRuhsWE4/kBrbH7bD5e//Uwftt/AY/ER2LJznNYfSgTJrMVpaaqWh6TxYo3lh/BP3s1R3axEQCw71wB8ktN8HXXAgCOZhbh042n8cQd0diUehEAsDk1F9nFFVIo23U2H6sOZmB0fNQ1Z2c+nVsq1TBtPXWR4YaI6AYw3FCD8ebwjuje3B+HLxThcEYRCssrMecfMdBrVOjcxBs/X6p56dTEG62CPdGpiQ+W7buAPWkFuOfDLTWu17dNENYfz8Gaw1nILKyQtgtRtTjo0M5hyCyswOgF25FdbMTe9HzkllQFIKsAlu/PwJjbovDK0oP437aqZqbU7BJ8PrbbVe/haGaR9PPWUxcx/vbmDnk2RESNCcMNNRi+7lqMjo+qdd8tl5aF8NCpER3oIW0fc1sU9qTtBQB0buKN5we0QaCnDnmlJsQ180PSyiP49M/TOHC+EEBVTVBqdgmW789AUUUlPvvztFSjczKnqmZIrVTAbBVYuvcCWod44n/b0qSh7xuO5+BCQTnCfNxqLeeRjMvhZvvpPFisAiql4rr3brUKLD+QgbjmflJtERFRY8VwQ41Cx3BvTB/SDk39DDZh4a4OoVjdMQtebhrMGFpzaPhLd7WFu06N95NPwMegxUsD22D8lzux6lAmVh2qWjQ0wEOLJr4Gacj5uJ7N8Nmm09iXXoApi/cBAEbFReJ4VjG2nc7DB+tSEe7jBoNWhdYhnugW5SeNvjqSUSx9dlGFGUcyiuxqmvpx9zk8/8N+dGrijWWTekChqLpHIQRWHsxETITPVQMVEVFDw3BDjYJCocCjPZvV2K5VKzFv1C1XPU+lVOCZhFYY0ikMOrUSgZ46RPkbcC6/HO3DvDCkUxjui22CvekFGLtoBwDg7pgwGLRqzPnjODKLKqBWKvDP3s2x40wetp3Ok5qoqvm5a/H2PR3Rv30Ijl6qufF31+JiqQkfrk9F71aBCPbSo3tz/6vOy/Pr/gwAwP5zhUg+ko2EdsEAqiY4fPHHA7g1yhdLJt521fvcdCIX+84VQAiBCb2a11j3K7u4AvfPT0Gghw6zhnVAu7CrD8NcdTADX6acxTv3duLq70QkC4YbIju0CLrclJU8tQ8qLVaboNG7VSCGdg6DAkDbEC+0DfHCwQuFWHM4C/fcEo4mvgYEeOjw9sqjyCoy4vaWAXDXqrHt9EXklZrw7OK9+Pax7rhwqW/PqO6R0mzKKw5U1RC1CfHEp6O7IsLPgNTsYpQYLejcxBuF5ZXYkporlWVu8nH0bRsEIYCPN54CUDWB4fmCcoTXUnvzx+EsjP9yp/S+0iLwbL9WNses2J+BsxfLcPZiGe7+YBM+ejgW/S4FqCtlFlbguSX7UWI048P1J5F0T0eb/RarwNsrjyDE2w3jagmb9jCaLfjzeC56tw6sda2zG2UyW20WhCWi+ovhhqiOVEoFVErbmg2lUoH/PtjFZtt/H+yC9cey0atVIICq4e2/Tu6JMpMFUQHuAKpWWR/12TZsP52HsZ9X1fw08XXDxN7NoVMrkXaxDDklRuxNL8DRzGL0/c8GhHjrkZZXBqCqua1TE2+YrQJR/gbkFBtx8HwRvkw5i3AfN5zKuTyHz8oDGRh/e3NsTs3FnydyMa5nMwR4aDF7zXEAVeHpaGYx5m84iftim9jUuqw/ngMACL608OnT3+3BkonxaB92ucnMaLZgxi8HpdFev+w9j1cGt4XHFau7rz+WjU//PC2VvVuzui90OmfNCczfcBLjejbDa0Pa2XVOUUUlnl+yD6VGCz4ZHQuD1vavvlUHMzD5f3vwz97N8fwA+xZsJaKbF2coJpLZ+YJyDPq/P6UV0fu1C8anV8yyDFQt/vn417ulfj1qpQIalVJalgIAnk1oBU+9GrN+OwytSgkfgwbZxUaEeetxobACtzT1waeju6L3e+tRYjQjwEOLfu1C8O32NLhrVdj04p144pvdSDl1EU183TCiSzgGdQxFswB3dJ65GkazFb892RNvrzyKTam5aOpnwOpne0GvUWHJznS8teII8ssqoVIq4O+uRXaxEcNjwuCuU+Opvi0R7KXHP7/aid8PZQGomrPotyd71tph+khGEfQaFZpdCoHVrFaBHu+sRUZhBdw0Kmx56U4YzVYEe+mkfkZ/VVheidELtmHfuapO4ZPuiLYJMNnFFeg/ZyMKyqqe/8iuEdiUmounE1riH5cWeiUi+dXl9zfDDdFNID2vDMv2nsfRzGI81qs5OjXxqXGMEAJpeWU4c7EM7UK9oFIq8Omfp/DFljMQAljx9O2I8jdgwpe78MeRqgDRxNcN8x+OxdAPNkEIoFerQGw8ngOFompIe7Un+kTjhYFtcCKrGPd/nCL9ogeA6EB3nMwpRai3HlteuhNFFWYMmLMRmUUVeOrOFgjw1GH6skMAgBAvPab2b4X8MhPeWnFUukaXpj74cNQtuP2ddTBbBQxaFcpMFkzsHY0XB7aWgonVKjDnj+P479pUeOnV+PPFO+HtppGusyctHyOuGLYf6q1HRmEFBrQPxn/+EWNTS1Tt1aUH8PXWNOkztSolfn+2F5oFuCOv1IRJlwLdlUt9AECQpw5bXrrT6UttXCwxwlOvYZMY0XUw3FwDww01NEUVlagwWRDkVTUEvLCsEh+sO4HoQA8M7xIOvUaF8V/swB9XLDD6+ZhbcTq3FHvTCyAAvDG8gxQiiisqkXwkGysOZGD98RyYLv3Cf7BbBJLu6QQA+G3/BUz+3x6bcozr2QwvD2oLlVKB/FITRny4GQCQV2pCUYUZgZ465BQb0TnCB6O7R2LqkqqRZP3aBSPQUwe1UoENx3Nw9mKZdM1XB1ddL6vIiJgIb2xKzcXXW9MQ5KmThuBXi/Bzw4Tbm0MBICrAHbe3DMS5/DLc8e/1qLQI/G98HOZvPIWNx3PQNtQLj/eJxqxfDyO3xAitWokfJ96GpJVHcDKnBGUmC4orzFiQ2BV929bsW+QoP+85h+eW7EfvVoFYOOZWm31pF8vg666Bp15zlbOJGheGm2tguKHGqMxkxrurjmHRljMY3DH0miPErnQkowjjv9iJ8wXl+PLRblL/ISEExny+AxuO58BLr8a4ns3xVN8WtTYNJR/JwrgvLndY/vf9nXFfbBN89ucpvLH8SI3jPXVq9GgRgFWHMmvUplT74KEu+Hn3eZQYzXgorineXnkUGVdMtAhUzWF0Lr8cfxzJQo8W/vhmfHek55VhxIdbpMkWAaBlkAdm/yMGHZt4o/qvwzeWH8GCTadrLMRamwsF5Xht6UEM6xKOuzuH1XrM+YJyzPzlEHq1CsTD3SMBVAWbKd/vk2rQlj/VE95uGgR46HDoQiH+8fFWtA72xLLJPRzacZqovmK4uQaGG2rMCssq4aFX2zUxYLXiikqcyilF5wgfm+0VlRYczypGmxCv6zap7Dqbj+yiCoR46xET4SOFoD9P5ODg+SIYzRaYzFY0C3DH4E6hEALo/lYyii91Tk5oG4xTOSU4lVuKAA8d/nzhDrhpL3fqLjWa8e32NKw8mAm9RonNl5bBqPbj47ch9tJEjkcyijDy4xQUG80Y37MZpvZvXWOI/fGsYvSfsxEAEOChw6i4pvjHrRFYtvc89qcXwioEhsWEo2/bICQu3I5tp/OgVSnxw+PxUpNiUUUl/jyeC1+DBv9afkSaoPG1Ie3grlXh5Z8PwCoAH4MGBWWVaB7ojlM5pWgV7AEPnRq70woAVNVeVc9UXWo045ONp9AuzAsDLi1NYjJbkVdqqrXfUfU8R3mlJjQPcEdslG+NYf72MF9ahkSpUOCVS7VpRK7GcHMNDDdE9cPbK49i/oaTGBXXFG8M7wCgahZoT70awV7XnoV52d7zmPvHCUT5G3BfbAQGdwq12Z9dVIFSk6VGh+UrTfrfbiy/NH/Q1bhrVSg1Xe7UHeqtx32xTXA8qxjrj+XY1Dpp1Uqpia/ag90i8I+uETb9iP7KQ6fGk3e2QKCnDp/9eRqHM4qgUACvD22PY1nFWL4/A4XlVeFoaKcw9GoVgLzSSgR56vDniRz8e/Vx6VpeejUGdghBfLQ/jmWWINzXDSO7Rlw1nBrNFigVCvx79TF8vKFqWoFnElpiYu9oCAEpYBZXVGLbqTx0j/aHh06N7OIKfLjuJC6WmtCvXTA8dCp46DTo1MQbeo0KQgiYLNZrBq2LJUbsTitA62BPNPW3f74kIQRKjGYYtFUh/lx+GdYezUaLQA/ER/tfteM53fwYbq6B4Yaofqi0WHEssxjtw7xk+4VU3f/otWUHUVxhxq1RvhjQPgQFZZX4fme61O/nhYGt8e32NKTnlduc3zzAHYXllTCZrVj06K1YdzQH3+1Ih1UI3BfbBC8NbAOlUoEHPknB1lN5uKdLOH47kAGT2YpHezTDnvR87LlUg1NNo1Kg0lK3v7a7N/fDqZzSGv2UACDK34C+bYORnleG3Wn58HLTQKNUorC8ElnFFVAqFLBYL3+eQgFpW4iXHpH+BhzOKEJxhRnBXjrcFh2A1YcybULflWV316lhrLSivNKCpn4G+HtokZpdAqPZigB3LXq3DsKJrGLsSsuXmuyi/A3QqJSIDvRAmI8bMovKUW6ywE2rQodwbzQP8IBOo8SRjCJ8vyMdZy7129Jrqpo1q68TG+mLwR1DYdCqUGKs6gdWvVzJoQuF8NJrEOqjR3peOSoqLdColfA1aJBVZERuiREdwrwR5KWDxSpQXmnB0j3ncSyzGEM7h1VNvZBbikg/A7zcNLAKgXAfN5QazTiXXw6NuuqZ5hYbEeChRbCXHh56NU5ml0AACPN2g8lihVKhgLtOhaJyM7RqJUK89Ki0WpFdZEROcQVCvN0Q6q2HQatCTrERJosVBq0auSVGVFqs8HHTwseggVqlQKnRAkAAqPrzU2o0Q6lQwN9DixKjGWUmCzRKBVRKBdQqJTQqBQxaNZQKSFM6qJVK6TtXYbbAWGmF0WyB0WyFyWyFr0ELv0uLCFuFgBBV/zVoVWgZ7Fmn7+n1MNxcA8MNEdXVxRIjcktMaB1y+S9rs8WKdcdyUGYy4+7OYcgvq8Rv+y9gb3oBmvoZkNA2GO3DvCAEYBHimv1mCssqceZiKTo18cb6YzlYcyQLL93VBgoA3+88h5STF2E0WxDipcdTfVsiaeURrDiQiYS2QRjboxk6hHkj+WgWft13AQfOFyHYS4czuaUoNVnwTEJLPJPQCharwI4zefhl3wUcPF+IlkGe2HA8x6b/0bWM69kMxRWV+H7nuVr3/7VmqnOED+Ka+eHPE7lQKxXILKpATi3h6lqi/A1IyyuD9W/+luoc4YMjGUU1as7IeWIjffHj41efFf1GMNxcA8MNEdV3QggUlZvhbbj6SKqKSguyi4zXbNIprqjEqoOZOHShCF5uGvRuFQiT2QqLVcDLTY0wHzdYrAK5JUa0C/WCVQA7z+Shqb8BbhoVTueW4nRuKfzctYhr5o+vt55FTokRfVoHonszfyiv6JsjhMCFwgqUm8zQqJRw16lx4HwhSirMaB3iCXedGkcuFGFTai6igzzQt00QwnzckF1cgZPZpai0WHHoQhHySo0I93GDu06N/DITDpwvQlpeGYyVFkT6G9C7VRAGdwyFRQiUGs3QqZUI8tIjs7ACv+67gD9Tc6FSAO66qtqO7CIjjGYrOoR7oajcjOziCjT1M8BDr4Gx0oK8UhP83LXw99Dh4PlClBrNUu1Vx3BvdIn0xZKd6RACaBvqibS8MlRUWiEAnM8vg06tQlSAARargIdOjUBPHS6WmJBVVHGpOdEDKqUCmYUV0GuUsFgFykwWeOrVqKi0IquoAjqNEn7uOgR66JBRWI6cYiPKTBYEeGihU6ukeat0GhUKyyqRX2aC2SrgrlNBqVBACEBAwF2rhlUI5JaY4KlXw12rhsUqUGm1wmwRqLRYUWaywGoV8NBXTatQaREwW63QqJTQqZXQa1TQqat+VquUyC81Ib+sEgpFVf2QUlFVE9Qh3AsfP3Ltzvh1xXBzDQw3RERE9U9dfn9zfCERERE1KAw3RERE1KAw3BAREVGDwnBDREREDQrDDRERETUoDDdERETUoDDcEBERUYPCcENEREQNCsMNERERNSgMN0RERNSgMNwQERFRg8JwQ0RERA0Kww0RERE1KAw3RERE1KCo5S6AqwkhAFQtnU5ERET1Q/Xv7erf49fS6MJNcXExACAiIkLmkhAREVFdFRcXw9vb+5rHKIQ9EagBsVqtuHDhAjw9PaFQKBx67aKiIkRERCA9PR1eXl4OvXZDw2dVN3xe9uOzsh+fVd3wednPGc9KCIHi4mKEhYVBqbx2r5pGV3OjVCrRpEkTp36Gl5cXv/h24rOqGz4v+/FZ2Y/Pqm74vOzn6Gd1vRqbauxQTERERA0Kww0RERE1KAw3DqTT6TBjxgzodDq5i3LT47OqGz4v+/FZ2Y/Pqm74vOwn97NqdB2KiYiIqGFjzQ0RERE1KAw3RERE1KAw3BAREVGDwnBDREREDQrDjYPMmzcPUVFR0Ov1iIuLw/bt2+Uu0k3h9ddfh0KhsHm1adNG2l9RUYFJkybB398fHh4euPfee5GVlSVjiV1n48aNGDp0KMLCwqBQKLB06VKb/UIITJ8+HaGhoXBzc0NCQgJOnDhhc0xeXh5GjRoFLy8v+Pj4YNy4cSgpKXHhXbjG9Z7VmDFjanzPBg4caHNMY3lWSUlJuPXWW+Hp6YmgoCAMHz4cx44dsznGnj93aWlpGDx4MAwGA4KCgvD888/DbDa78lZcwp7n1adPnxrfr4kTJ9oc0xie10cffYROnTpJE/PFx8dj5cqV0v6b6XvFcOMAixcvxpQpUzBjxgzs3r0bnTt3xoABA5CdnS130W4K7du3R0ZGhvTatGmTtO/ZZ5/Fr7/+iiVLlmDDhg24cOEC7rnnHhlL6zqlpaXo3Lkz5s2bV+v+d999F++//z7mz5+Pbdu2wd3dHQMGDEBFRYV0zKhRo3Do0CGsWbMGv/32GzZu3IjHHnvMVbfgMtd7VgAwcOBAm+/Zt99+a7O/sTyrDRs2YNKkSdi6dSvWrFmDyspK9O/fH6WlpdIx1/tzZ7FYMHjwYJhMJmzZsgVffPEFFi1ahOnTp8txS05lz/MCgAkTJth8v959911pX2N5Xk2aNMHbb7+NXbt2YefOnbjzzjsxbNgwHDp0CMBN9r0S9Ld169ZNTJo0SXpvsVhEWFiYSEpKkrFUN4cZM2aIzp0717qvoKBAaDQasWTJEmnbkSNHBACRkpLiohLeHACIn3/+WXpvtVpFSEiIeO+996RtBQUFQqfTiW+//VYIIcThw4cFALFjxw7pmJUrVwqFQiHOnz/vsrK72l+flRBCJCYmimHDhl31nMb6rIQQIjs7WwAQGzZsEELY9+duxYoVQqlUiszMTOmYjz76SHh5eQmj0ejaG3Cxvz4vIYTo3bu3ePrpp696TmN+Xr6+vuKzzz676b5XrLn5m0wmE3bt2oWEhARpm1KpREJCAlJSUmQs2c3jxIkTCAsLQ/PmzTFq1CikpaUBAHbt2oXKykqbZ9emTRs0bdq00T+706dPIzMz0+bZeHt7Iy4uTno2KSkp8PHxQdeuXaVjEhISoFQqsW3bNpeXWW7r169HUFAQWrdujccffxwXL16U9jXmZ1VYWAgA8PPzA2Dfn7uUlBR07NgRwcHB0jEDBgxAUVGR9K/0huqvz6vaN998g4CAAHTo0AHTpk1DWVmZtK8xPi+LxYLvvvsOpaWliI+Pv+m+V41u4UxHy83NhcVisfmfBQDBwcE4evSoTKW6ecTFxWHRokVo3bo1MjIyMHPmTNx+++04ePAgMjMzodVq4ePjY3NOcHAwMjMz5SnwTaL6/mv7XlXvy8zMRFBQkM1+tVoNPz+/Rvf8Bg4ciHvuuQfNmjXDyZMn8fLLL+Ouu+5CSkoKVCpVo31WVqsVzzzzDHr06IEOHToAgF1/7jIzM2v97lXva6hqe14A8NBDDyEyMhJhYWHYv38/XnzxRRw7dgw//fQTgMb1vA4cOID4+HhUVFTAw8MDP//8M9q1a4e9e/feVN8rhhtyqrvuukv6uVOnToiLi0NkZCS+//57uLm5yVgyakgeeOAB6eeOHTuiU6dOiI6Oxvr169G3b18ZSyavSZMm4eDBgzb93Ojqrva8ruyb1bFjR4SGhqJv3744efIkoqOjXV1MWbVu3Rp79+5FYWEhfvjhByQmJmLDhg1yF6sGNkv9TQEBAVCpVDV6hGdlZSEkJESmUt28fHx80KpVK6SmpiIkJAQmkwkFBQU2x/DZQbr/a32vQkJCanRaN5vNyMvLa/TPr3nz5ggICEBqaiqAxvmsJk+ejN9++w3r1q1DkyZNpO32/LkLCQmp9btXva8hutrzqk1cXBwA2Hy/Gsvz0mq1aNGiBWJjY5GUlITOnTvj//7v/2667xXDzd+k1WoRGxuL5ORkaZvVakVycjLi4+NlLNnNqaSkBCdPnkRoaChiY2Oh0Whsnt2xY8eQlpbW6J9ds2bNEBISYvNsioqKsG3bNunZxMfHo6CgALt27ZKOWbt2LaxWq/SXb2N17tw5XLx4EaGhoQAa17MSQmDy5Mn4+eefsXbtWjRr1sxmvz1/7uLj43HgwAGbQLhmzRp4eXmhXbt2rrkRF7ne86rN3r17AcDm+9VYntdfWa1WGI3Gm+975dDuyY3Ud999J3Q6nVi0aJE4fPiweOyxx4SPj49Nj/DGaurUqWL9+vXi9OnTYvPmzSIhIUEEBASI7OxsIYQQEydOFE2bNhVr164VO3fuFPHx8SI+Pl7mUrtGcXGx2LNnj9izZ48AIGbPni327Nkjzp49K4QQ4u233xY+Pj5i2bJlYv/+/WLYsGGiWbNmory8XLrGwIEDRZcuXcS2bdvEpk2bRMuWLcWDDz4o1y05zbWeVXFxsXjuuedESkqKOH36tPjjjz/ELbfcIlq2bCkqKiqkazSWZ/X4448Lb29vsX79epGRkSG9ysrKpGOu9+fObDaLDh06iP79+4u9e/eKVatWicDAQDFt2jQ5bsmprve8UlNTxaxZs8TOnTvF6dOnxbJly0Tz5s1Fr169pGs0luf10ksviQ0bNojTp0+L/fv3i5deekkoFAqxevVqIcTN9b1iuHGQ//73v6Jp06ZCq9WKbt26ia1bt8pdpJvCyJEjRWhoqNBqtSI8PFyMHDlSpKamSvvLy8vFE088IXx9fYXBYBAjRowQGRkZMpbYddatWycA1HglJiYKIaqGg7/22msiODhY6HQ60bdvX3Hs2DGba1y8eFE8+OCDwsPDQ3h5eYmxY8eK4uJiGe7Gua71rMrKykT//v1FYGCg0Gg0IjIyUkyYMKHGPy4ay7Oq7TkBEJ9//rl0jD1/7s6cOSPuuusu4ebmJgICAsTUqVNFZWWli+/G+a73vNLS0kSvXr2En5+f0Ol0okWLFuL5558XhYWFNtdpDM/r0UcfFZGRkUKr1YrAwEDRt29fKdgIcXN9rxRCCOHYuiAiIiIi+bDPDRERETUoDDdERETUoDDcEBERUYPCcENEREQNCsMNERERNSgMN0RERNSgMNwQERFRg8JwQ0SNnkKhwNKlS+UuBhE5CMMNEclqzJgxUCgUNV4DBw6Uu2hEVE+p5S4AEdHAgQPx+eef22zT6XQylYaI6jvW3BCR7HQ6HUJCQmxevr6+AKqajD766CPcddddcHNzQ/PmzfHDDz/YnH/gwAHceeedcHNzg7+/Px577DGUlJTYHLNw4UK0b98eOp0OoaGhmDx5ss3+3NxcjBgxAgaDAS1btsQvv/zi3JsmIqdhuCGim95rr72Ge++9F/v27cOoUaPwwAMP4MiRIwCA0tJSDBgwAL6+vtixYweWLFmCP/74wya8fPTRR5g0aRIee+wxHDhwAL/88gtatGhh8xkzZ87EP/7xD+zfvx+DBg3CqFGjkJeX59L7JCIHcfhSnEREdZCYmChUKpVwd3e3eb355ptCiKpVmydOnGhzTlxcnHj88ceFEEJ88sknwtfXV5SUlEj7ly9fLpRKpbQyeFhYmHjllVeuWgYA4tVXX5Xel5SUCABi5cqVDrtPInId9rkhItndcccd+Oijj2y2+fn5ST/Hx8fb7IuPj8fevXsBAEeOHEHnzp3h7u4u7e/RowesViuOHTsGhUKBCxcuoG/fvtcsQ6dOnaSf3d3d4eXlhezs7Bu9JSKSEcMNEcnO3d29RjORo7i5udl1nEajsXmvUChgtVqdUSQicjL2uSGim97WrVtrvG/bti0AoG3btti3bx9KS0ul/Zs3b4ZSqUTr1q3h6emJqKgoJCcnu7TMRCQf1twQkeyMRiMyMzNttqnVagQEBAAAlixZgq5du6Jnz5745ptvsH37dixYsAAAMGrUKMyYMQOJiYl4/fXXkZOTgyeffBKPPPIIgoODAQCvv/46Jk6ciKCgINx1110oLi7G5s2b8eSTT7r2RonIJRhuiEh2q1atQmhoqM221q1b4+jRowCqRjJ99913eOKJJxAaGopvv/0W7dq1AwAYDAb8/vvvePrpp3HrrbfCYDDg3nvvxezZs6VrJSYmoqKiAnPmzMFzzz2HgIAA3Hfffa67QSJyKYUQQshdCCKiq1EoFPj5558xfPhwuYtCRPUE+9wQERFRg8JwQ0RERA0K+9wQ0U2NLedEVFesuSEiIqIGheGGiIiIGhSGGyIiImpQGG6IiIioQWG4ISIiogaF4YaIiIgaFIYbIiIialAYboiIiKhBYbghIiKiBuX/AZ1l80WNtX4UAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(val_loss_history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss (MSE)\")\n",
    "plt.title(\"Training Loss vs Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "be0e6a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Réelle : 0.3112\n",
      "R² Réel    : 0.7613\n"
     ]
    }
   ],
   "source": [
    "dsn.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_scaled = dsn(X_test_t) \n",
    "\n",
    "y_pred_real = (y_pred_scaled * y_std) + y_mean\n",
    "\n",
    "y_true_real = (y_test_t * y_std) + y_mean\n",
    "\n",
    "\n",
    "y_pred = y_pred_real.cpu().numpy() \n",
    "y_true = y_true_real.cpu().numpy()\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MSE Réelle : {mse:.4f}\")\n",
    "print(f\"R² Réel    : {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c305dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 242, 'name': 'Energy Efficiency', 'repository_url': 'https://archive.ics.uci.edu/dataset/242/energy+efficiency', 'data_url': 'https://archive.ics.uci.edu/static/public/242/data.csv', 'abstract': 'This study looked into assessing the heating load and cooling load requirements of buildings (that is, energy efficiency) as a function of building parameters.', 'area': 'Computer Science', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Multivariate'], 'num_instances': 768, 'num_features': 8, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Y1', 'Y2'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2012, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C51307', 'creators': ['Athanasios Tsanas', 'Angeliki Xifara'], 'intro_paper': {'ID': 379, 'type': 'NATIVE', 'title': 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', 'authors': 'A. Tsanas, Angeliki Xifara', 'venue': 'Energy and Buildings, vol. 49', 'year': 2012, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/Accurate-quantitative-estimation-of-energy-of-using-Tsanas-Xifara/719e65379c5959141180a45f540f707d583b8ce2', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'We perform energy analysis using 12 different building shapes simulated in Ecotect. The buildings differ with respect to the glazing area, the glazing area distribution, and the orientation, amongst other parameters. We simulate various settings as functions of the afore-mentioned characteristics to obtain 768 building shapes. The dataset comprises 768 samples and 8 features, aiming to predict two real valued responses. It can also be used as a multi-class classification problem if the response is rounded to the nearest integer.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The dataset contains eight attributes (or features, denoted by X1...X8) and two responses (or outcomes, denoted by y1 and y2). The aim is to use the eight features to predict each of the two responses.\\r\\n\\r\\nSpecifically:\\r\\nX1\\tRelative Compactness\\r\\nX2\\tSurface Area\\r\\nX3\\tWall Area\\r\\nX4\\tRoof Area\\r\\nX5\\tOverall Height\\r\\nX6\\tOrientation\\r\\nX7\\tGlazing Area\\r\\nX8\\tGlazing Area Distribution\\r\\ny1\\tHeating Load\\r\\ny2\\tCooling Load', 'citation': None}}\n",
      "  name     role        type demographic                description units  \\\n",
      "0   X1  Feature  Continuous        None       Relative Compactness  None   \n",
      "1   X2  Feature  Continuous        None               Surface Area  None   \n",
      "2   X3  Feature  Continuous        None                  Wall Area  None   \n",
      "3   X4  Feature  Continuous        None                  Roof Area  None   \n",
      "4   X5  Feature  Continuous        None             Overall Height  None   \n",
      "5   X6  Feature     Integer        None                Orientation  None   \n",
      "6   X7  Feature  Continuous        None               Glazing Area  None   \n",
      "7   X8  Feature     Integer        None  Glazing Area Distribution  None   \n",
      "8   Y1   Target  Continuous        None               Heating Load  None   \n",
      "9   Y2   Target  Continuous        None               Cooling Load  None   \n",
      "\n",
      "  missing_values  \n",
      "0             no  \n",
      "1             no  \n",
      "2             no  \n",
      "3             no  \n",
      "4             no  \n",
      "5             no  \n",
      "6             no  \n",
      "7             no  \n",
      "8             no  \n",
      "9             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "energy_efficiency = fetch_ucirepo(id=242) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = energy_efficiency.data.features \n",
    "y = energy_efficiency.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(energy_efficiency.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(energy_efficiency.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c5c8455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([614, 8])\n",
      "torch.Size([614, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y[\"Y1\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "X_train_t = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "X_test_t  = torch.tensor(X_test.to_numpy(),  dtype=torch.float32)\n",
    "\n",
    "# Avant le training\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std()\n",
    "y_train_scaled = (y_train - y_mean) / y_std\n",
    "y_test_scaled = (y_test - y_mean) / y_std\n",
    "\n",
    "y_train_t = torch.tensor(y_train_scaled.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "y_test_t = torch.tensor(y_test_scaled.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(X_train_t.shape)  # (N_train, d_input)\n",
    "print(y_train_t.shape)  # (N_train, 1)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "eba0fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(\n",
    "        hidden_layer_sizes=(256,128, 64),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        alpha=1e-4,\n",
    "        batch_size=256,\n",
    "        learning_rate_init=1e-3,\n",
    "        max_iter=5000,\n",
    "        early_stopping=True,\n",
    "        random_state=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8dcfd784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 14.008745652864592\n",
      "R²: 0.8655997566405411\n",
      "43521\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "def count_params_mlp(model):\n",
    "    return sum(w.size + b.size for w, b in zip(model.coefs_, model.intercepts_))\n",
    "print(count_params_mlp(mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4282a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "dsn = dsn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "202b2a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de paramètres : 913\n",
      "Paramètres de la première couche : 216\n"
     ]
    }
   ],
   "source": [
    "d_input = X_train.shape[1]\n",
    "epochs = 50\n",
    "learning_rate = 1e-3\n",
    "n_samples = X.shape[0]\n",
    "batch_size = 128\n",
    "\n",
    "dims = [d_input,16,8,8,1]\n",
    "dsn = DeepSpectralNet(dims, ortho_mode=None,use_layernorm=True)\n",
    "\n",
    "# 1. Obtenir le nombre total de paramètres\n",
    "total_params = dsn.num_parameters\n",
    "print(f\"Nombre total de paramètres : {total_params}\")\n",
    "\n",
    "# 2. Vérifier une couche spécifique\n",
    "layer_params = dsn.layers[0].num_parameters\n",
    "print(f\"Paramètres de la première couche : {layer_params}\")\n",
    "\n",
    "# ==== Optimiseur et loss ====\n",
    "optimizer = torch.optim.AdamW(dsn.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=100\n",
    ")\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ecf28c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 | Train Loss: 0.082720 | Val Loss: 0.099386 | LR: 0.001000\n",
      "Epoch 21/1000 | Train Loss: 0.025868 | Val Loss: 0.023124 | LR: 0.001000\n",
      "Epoch 41/1000 | Train Loss: 0.024879 | Val Loss: 0.019192 | LR: 0.001000\n",
      "Epoch 61/1000 | Train Loss: 0.022790 | Val Loss: 0.020812 | LR: 0.001000\n",
      "Epoch 81/1000 | Train Loss: 0.024884 | Val Loss: 0.019083 | LR: 0.001000\n",
      "Epoch 101/1000 | Train Loss: 0.022810 | Val Loss: 0.020353 | LR: 0.001000\n",
      "Epoch 121/1000 | Train Loss: 0.023237 | Val Loss: 0.017477 | LR: 0.001000\n",
      "Epoch 141/1000 | Train Loss: 0.024263 | Val Loss: 0.021072 | LR: 0.001000\n",
      "Epoch 161/1000 | Train Loss: 0.020715 | Val Loss: 0.016184 | LR: 0.001000\n",
      "Epoch 181/1000 | Train Loss: 0.029602 | Val Loss: 0.024228 | LR: 0.001000\n",
      "Epoch 201/1000 | Train Loss: 0.023445 | Val Loss: 0.020833 | LR: 0.001000\n",
      "Epoch 221/1000 | Train Loss: 0.022477 | Val Loss: 0.022390 | LR: 0.001000\n",
      "Epoch 241/1000 | Train Loss: 0.024456 | Val Loss: 0.018218 | LR: 0.001000\n",
      "Epoch 261/1000 | Train Loss: 0.021566 | Val Loss: 0.017957 | LR: 0.001000\n",
      "Epoch 281/1000 | Train Loss: 0.010943 | Val Loss: 0.012469 | LR: 0.000100\n",
      "Epoch 301/1000 | Train Loss: 0.010873 | Val Loss: 0.012016 | LR: 0.000100\n",
      "Epoch 321/1000 | Train Loss: 0.010000 | Val Loss: 0.011051 | LR: 0.000100\n",
      "Epoch 341/1000 | Train Loss: 0.009881 | Val Loss: 0.011368 | LR: 0.000100\n",
      "Epoch 361/1000 | Train Loss: 0.009215 | Val Loss: 0.010962 | LR: 0.000100\n",
      "Epoch 381/1000 | Train Loss: 0.010266 | Val Loss: 0.010207 | LR: 0.000100\n",
      "Epoch 401/1000 | Train Loss: 0.008698 | Val Loss: 0.010193 | LR: 0.000100\n",
      "Epoch 421/1000 | Train Loss: 0.009156 | Val Loss: 0.010208 | LR: 0.000100\n",
      "Epoch 441/1000 | Train Loss: 0.008436 | Val Loss: 0.009926 | LR: 0.000100\n",
      "Epoch 461/1000 | Train Loss: 0.008547 | Val Loss: 0.010730 | LR: 0.000100\n",
      "Epoch 481/1000 | Train Loss: 0.008646 | Val Loss: 0.009140 | LR: 0.000100\n",
      "Epoch 501/1000 | Train Loss: 0.008479 | Val Loss: 0.009899 | LR: 0.000100\n",
      "Epoch 521/1000 | Train Loss: 0.008189 | Val Loss: 0.009506 | LR: 0.000100\n",
      "Epoch 541/1000 | Train Loss: 0.007818 | Val Loss: 0.008756 | LR: 0.000100\n",
      "Epoch 561/1000 | Train Loss: 0.008268 | Val Loss: 0.009311 | LR: 0.000100\n",
      "Epoch 581/1000 | Train Loss: 0.007556 | Val Loss: 0.009329 | LR: 0.000100\n",
      "Epoch 601/1000 | Train Loss: 0.007797 | Val Loss: 0.009261 | LR: 0.000100\n",
      "Epoch 621/1000 | Train Loss: 0.007326 | Val Loss: 0.009306 | LR: 0.000100\n",
      "Epoch 641/1000 | Train Loss: 0.007143 | Val Loss: 0.008321 | LR: 0.000100\n",
      "Epoch 661/1000 | Train Loss: 0.007673 | Val Loss: 0.008218 | LR: 0.000100\n",
      "Epoch 681/1000 | Train Loss: 0.008021 | Val Loss: 0.010907 | LR: 0.000100\n",
      "Epoch 701/1000 | Train Loss: 0.008121 | Val Loss: 0.011049 | LR: 0.000100\n",
      "Epoch 721/1000 | Train Loss: 0.007711 | Val Loss: 0.007887 | LR: 0.000100\n",
      "Epoch 741/1000 | Train Loss: 0.007218 | Val Loss: 0.008431 | LR: 0.000100\n",
      "Epoch 761/1000 | Train Loss: 0.006804 | Val Loss: 0.007399 | LR: 0.000100\n",
      "Epoch 781/1000 | Train Loss: 0.006672 | Val Loss: 0.007118 | LR: 0.000100\n",
      "Epoch 801/1000 | Train Loss: 0.006629 | Val Loss: 0.007140 | LR: 0.000100\n",
      "Epoch 821/1000 | Train Loss: 0.006729 | Val Loss: 0.007471 | LR: 0.000100\n",
      "Epoch 841/1000 | Train Loss: 0.006659 | Val Loss: 0.007566 | LR: 0.000100\n",
      "Epoch 861/1000 | Train Loss: 0.007166 | Val Loss: 0.006894 | LR: 0.000100\n",
      "Epoch 881/1000 | Train Loss: 0.006688 | Val Loss: 0.007158 | LR: 0.000100\n",
      "Epoch 901/1000 | Train Loss: 0.006346 | Val Loss: 0.006883 | LR: 0.000100\n",
      "Epoch 921/1000 | Train Loss: 0.006083 | Val Loss: 0.007017 | LR: 0.000100\n",
      "Epoch 941/1000 | Train Loss: 0.005793 | Val Loss: 0.006576 | LR: 0.000100\n",
      "Epoch 961/1000 | Train Loss: 0.007317 | Val Loss: 0.007577 | LR: 0.000100\n",
      "Epoch 981/1000 | Train Loss: 0.006116 | Val Loss: 0.006224 | LR: 0.000100\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ======== Training ========\n",
    "    dsn.train()\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for Xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = dsn(Xb)         \n",
    "        loss = criterion(y_pred, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(dsn.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "    scheduler.step(avg_train_loss)\n",
    "\n",
    "    # ======== Validation ========\n",
    "    dsn.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:  \n",
    "            y_pred = dsn(Xb)\n",
    "            loss = criterion(y_pred, yb)\n",
    "            total_val_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(test_loader.dataset)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "\n",
    "    # ======== Logging ========\n",
    "    if epoch % 20 == 0 or epoch == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.6f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.6f} | LR: {current_lr:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "54b9c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Start Training | Device: MPS | Total Epochs: 500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd182d388d3484282532cc0b221f0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progression:   0%|          | 0/500 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/500 | Train: 0.9984 | Val: 1.0364\n",
      "Epoch 200/500 | Train: 0.9984 | Val: 1.0366\n",
      "Epoch 300/500 | Train: 0.9984 | Val: 1.0363\n",
      "Epoch 400/500 | Train: 0.9984 | Val: 1.0367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/spectral-neural-network-SNN/Tool.py:64\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, epochs, scheduler, device, ortho_lambda, ortho_loss_fn, clip_grad_norm, log_interval)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip_grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip_grad_norm)\n\u001b[0;32m---> 64\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m Xb\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Cela permet de voir la loss bouger en temps réel.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    175\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    178\u001b[0m         group,\n\u001b[1;32m    179\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         state_steps,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 188\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 340\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/optim/adamw.py:473\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 473\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train_model(\n",
    "    model=dsn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2a21e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Réelle : 0.6379\n",
      "R² Réel    : 0.9939\n",
      "Nombre total de paramètres : 913\n"
     ]
    }
   ],
   "source": [
    "dsn.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_scaled = dsn(X_test_t) \n",
    "\n",
    "y_pred_real = (y_pred_scaled * y_std) + y_mean\n",
    "\n",
    "y_true_real = (y_test_t * y_std) + y_mean\n",
    "\n",
    "\n",
    "y_pred = y_pred_real.cpu().numpy() \n",
    "y_true = y_true_real.cpu().numpy()\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MSE Réelle : {mse:.4f}\")\n",
    "print(f\"R² Réel    : {r2:.4f}\")\n",
    "total_params = dsn.num_parameters\n",
    "print(f\"Nombre total de paramètres : {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
